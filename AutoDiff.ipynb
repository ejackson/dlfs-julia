{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "856bf911-6e61-4166-83ab-5ec023311bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux\n",
    "using Flux: update!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a168690-74c1-4e83-a175-d86d3b0cb085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So the construction for linear regression\n",
    "\n",
    "# Create our observed data\n",
    "fσ(x) = x ./ (1 .+ exp.(-1 .* x))\n",
    "Wₜ = [1.1; 2.2; 3.3; 4; 5]                  # The true weights.   We don't observe these.\n",
    "xₒ = rand(8,5)                             # Observed x\n",
    "yₒ = fσ(xₒ * Wₜ)                            # Observed y\n",
    "\n",
    "# The core regression\n",
    "regress(x, W) = fσ(x * W)                    # Classic linear regression\n",
    "regress(W) = regress(xₒ, W)                  # Close over the observed data\n",
    "\n",
    "# The loss function,\n",
    "loss(x, y, W) = sum((regress(x, W) .- y).^2)\n",
    "loss(W) = loss(xₒ, yₒ, W);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4bf34e2-05ec-498b-9456-467d082311f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5×1 Matrix{Float64}:\n",
       " 1.112074221721476\n",
       " 2.205466017258204\n",
       " 3.2778446054317927\n",
       " 4.007941741352166\n",
       " 4.99612555672165"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initiate Wᵢ to random values\n",
    "Wᵢ = rand(5,1)\n",
    "\n",
    "# Now take the automatic differential of the loss wrt W.  This is a dloss/dW\n",
    "dloss(W) = gradient(loss, W)[1]\n",
    "\n",
    "# Descent() returns a function which performs a single iteration of the gradient descent algorithm\n",
    "# I believe it is sometimes stateful, so we want to pull it out to give it global scope\n",
    "opt = Descent(0.0001);\n",
    "\n",
    "# update! uses that function to mutate the params Wᵢ with the gradient vector dloss(Wᵢ)\n",
    "for i=1:1E6\n",
    "    update!(opt, Wᵢ, dloss(Wᵢ))\n",
    "end\n",
    "\n",
    "Wᵢ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a52d73-6317-4f57-922d-86eab9657beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets try do it with a better optimization algorithm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.3",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
